myMatrix2
myMatrix2[1,]
myMatrix2
myMatrix2[1,]
myMatrix2[,1]
myMatrix2[2,3]
colnames(myMatrix2)<-c("liver","lung","kidney")
myMatrix2
myMatrix2["INS", "liver"]
myMatrix2["INS", "lung"]
myMatrix2<-c("lung", "liver")
myMatrix2<-c("lung", "liver")
e
myMatrix2["lung"]
myMatrix2<-c(colnames("liver", "lung", "kidney"))
myMatrix2<-c(colnames(e, e2, e3))
lungAndLiverData<-c(colnames(myMatrix2))
lungAndLiverData
lungAndLiverData<-c(myMatrix2["lung", "liver"])
lungAndLiverData<-c(myMatrix2[1, ])
myMatrix2["lung"]
myMatrix2
#and another
myMatrix2<-cbind(e,"e2"=e*2,"e3"=e*3)
myMatrix2
colnames(myMatrix2)<-c("liver","lung","kidney")
myMatrix2
myMatrix2
myMatrix2["lung"]
myMatrix2
colnames(myMatrix2)
colnames(myMatrix2)->columnNamesofmyMatrix2
columnNamesofmyMatrix2
columnNamesofmyMatrix2[1:2]
col1(myMatrix2)
myMatrix2LungsAndLiver<-myMatrix2["lung"]
myMatrix2LungsAndLiver
myMatrix2[ ,"lung"]
myMatrix2[ ,"lung"]
myMatrix2[ ,"liver"]
e <- c("red", "white", "red", NA)
d <- c(1,2,3,4)
e <- c("red", "white", "red", NA)
f <- c(TRUE,TRUE,TRUE,FALSE)
mydata <- data.frame(d,e,f)
names(mydata) <- c("myNumber","myWord","TorF") # variable names
mydata
mydata <- data.frame(d,e,f)
mydata
d <- c(1,2,3,4)
e <- c("red", "white", "red", NA)
f <- c(TRUE,TRUE,TRUE,FALSE)
mydata <- data.frame(d,e,f)
names(mydata) <- c("myNumber","myWord","TorF") # variable names
mydata
myDF<-as.data.frame(myMatrix2)
myDF
library(tidyverse)
apply(myMatrix2, 1, mean)
apply(myMatrix2, 2, mean)
apply(myMatrix2, 1, mean)
apply(myMatrix2, 2, mean)
apply(myMatrix2, 1, sum)
apply(myMatrix2, 1, 2, sum)
apply(myMatrix2, 1, sum)
apply(myMatrix2, 1, sum)
apply(myMatrix2, 2, sum)
#make a list
myList<-list(a,b,e,myMatrix2)
#make a list
myList<-list(b,e,myMatrix2)
#make a list
myList<-list(d,e,myMatrix2)
#view the list
myList
#lists can be names for easier access
names(myList)<-c("g2", "g3","g4")
#lists can be accessed
myList[1:3]
ListOf5Variables<-list("j", "k", "l", "m", "n")
ListOf5Variables[2]
ListOf5Variables<-list("j", "k", "l", "m", "n")
ListOf5Variables[2]
ListOf5Variables[2:4]
ListOf5Variables[2*4]
ListOf5Variables<-list(1:5)
ListOf5Variables[2]
ListOf5Variables[2:4]
ListOf5Variables<-list("1", "2", "3", "4", "5"")
ListOf5Variables[2]
ListOf5Variables[2:4]
ListOf5Variables<-list("1", "2", "3", "4", "5")
ListOf5Variables[2]
ListOf5Variables[2:4]
ListOf5Variables[2*4]
ListOf5Variables[2]*ListOf5Variables[4]
ListOf5Variables[[2]]
ListOf5Variables[[2]]*ListOf5Variables[[4]]
names(ListOf5Variables)<-c("variable1", "variable2", "variable3", "variable4", "variable5")
names(ListOf5Variables)<-c("variable1", "variable2", "variable3", "variable4", "variable5")
ListOf5Variables[variable1]
names(ListOf5Variables)<-c("variable1", "variable2", "variable3", "variable4", "variable5")
ListOf5Variables["variable1"]
for(counter in 1:3){
print(myMatrix2[counter,])
}
for(counter in 1:3){
print(myMatrix2[counter,])
}
myMatrix2
for(counter in 1:3){
print(mean(myMatrix2[ ,counter]))
}
for(counter 1:3) {
for(counter in 1:3) {
matrixFromAVector<-cbind(d)
}
matrixFromAVector
for(counter in 1:3) {
print(d)
}
matrixFromAVector
for(counter in 1:3) {
cbind(print(d))<-matrixFromAVector2
}
for(counter in 1:3) {
cbind(print(d))
}
matrixFromAVector
for(counter in 1:3) {
cbind(print(d))
}
for(counter in 1:3) {
z<-cbind(print(d))
}
z
z<-cbind(d, d, d)
z
for(counter in 1:3){
z<-cbind(d, d, d)
}
z
for(counter in 1:3){
z<-cbind(d)
}
z
for(counter in 1:3){
z<-cbind(d, d, d)
}
z
test=1
while(test < 6){
#do something...
print(test)
test=test+1
}
while(d<3){
print(d)
d=d+1
}
while(d<8){
print(d)
d=d+1
}
read.csv("myDataFile.csv")
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data"
data <- read.table(url, sep=",")
dim(data)
data(mtcars)
head(mtcars)
summary(mtcars)
head(data)
summary(data)
colnames(data)<-c("class", "age", "menopause", "tumorSize", "invNodes", "nodeCaps", "degMalig", "breast", "breastQuad", "irradiate")
head(data)
head(data$class)
levels(data$class)
#The split funciton can divide the data based on the category
dataSplit<-(split.data.frame(data,data$class))
summary(dataSplit[[1]])
summary(dataSplit[[2]])
while(d<11){
print(d)
d=d+1
}
d=1
while(d < 11){
print(d)
d=d+1
}
d=[8:11]
d->c(8:11)
d <- c(1,2,3,4)
e <- c("red", "white", "red", NA)
f <- c(TRUE,TRUE,TRUE,FALSE)
mydata <- data.frame(d,e,f)
names(mydata) <- c("myNumber","myWord","TorF") # variable names
mydata
print(d[1])
print(d[1])->c
c
while(c < 3){
print(d[1])->c
c=c+1
}
d[1+1]
while(d[]<3) {
print(d)
d=d+1
}
read.csv("myDataFile.csv")
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data"
data <- read.table(url, sep=",")
dim(data)
colnames(data)<-c("class", "age", "menopause", "tumorSize", "invNodes", "nodeCaps", "degMalig", "breast", "breastQuad", "irradiate")
head(data)
head(data$class)
#The split funciton can divide the data based on the category
dataSplit<-(split.data.frame(data,data$class))
#The split funciton can divide the data based on the category
dataSplit<-(split.data.frame(data,data$class))
summary(dataSplit[[1]])
summary(dataSplit[[2]])
dataSplit<-split.data.frame(data,data$irradiate)
summary(dataSplit[[1]])
summary(dataSplit[[2]])
url <- "https://archive.ics.uci.edu/ml/datasets.html""
url <- "https://archive.ics.uci.edu/ml/datasets.html""
url <- "https://archive.ics.uci.edu/ml/datasets.html"
data2 <- read.table(url, sep=",")
url <- "https://archive.ics.uci.edu/ml/datasets.html"
data2 <- read.table(url, sep=",")
dim(data2)
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.data"
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.data"
arrhytmiaData <- read.table(url, sep=",")
dim(data2)
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.data"
arrhytmiaData <- read.table(url, sep=",")
dim(arrhytmiaData)
colnames(balloonData)<-c("color", "size", "act", "age", "inflated")
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/balloons/yellow-small.data"
balloonData <- read.table(url, sep=",")
dim(balloonData)
colnames(balloonData)<-c("color", "size", "act", "age", "inflated")
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/balloons/yellow-small.data"
balloonData <- read.table(url, sep=",")
dim(balloonData)
colnames(balloonData)<-c("color", "size", "act", "age", "inflated")
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/balloons/yellow-small.data"
balloonData <- read.table(url, sep=",")
dim(balloonData)
colnames(balloonData)<-c("color", "size", "act", "age", "inflated")
head(balloonData)
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/balloons/yellow-small.data"
balloonData <- read.table(url, sep=",")
dim(balloonData)
colnames(balloonData)<-c("color", "size", "act", "age", "inflated")
head(balloonData)
balloonDataSplit<-split.data.frame(balloonData,balloonData$age)
summary(balloonDataSplit[[1]])
summary(balloonDataSplit[[2]])
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/balloons/yellow-small.data"
balloonData <- read.table(url, sep=",")
dim(balloonData)
colnames(balloonData)<-c("color", "size", "act", "age", "inflated")
head(balloonData)
balloonDataSplit<-split.data.frame(balloonData,balloonData$size)
summary(balloonDataSplit[[1]])
summary(balloonDataSplit[[2]])
help(runif)
runif()
x<-1:4
lapply(x, runif)
help(na.rm)
library(datasets)
data("iris")
?iris
apply(iris, 1, mean)
warnings()
apply(iris$Sepal.Length, 1, mean)
head(iris)
iris
f<-gl(3,50)
tapply(iris$Sepal.Length, f, mean)
apply(iris,2,mean)
colMeans(iris)
iris
apply(iris,1,mean)
rowMeans(iris[,1:4])
apply(iris[,1:4],1,mean)
apply(iris[,1:4],2,mean)
library(datasets)
data(mtcars)
?mtcars
apply(mtcars,2,mean)
sapply(mtcars(split(mtcars$mpg,mtcars$cyl),mean))
sapply(split(mtcars$mpg,mtcars$cyl),mean)
sapply(mtcars$mpg,mtcars$cyl,mean)
mtcars$cyl
split(mtcars,mtcars$cyl)
mean(mtcars$mpg,mtcars$cyl)
tapply(mtcars$cyl,mtcars$mpg,mean)
sapply(mtcars,cyl,mean)
lapply(mtcars,mean)
with(mtcars,tapply(mpg,cyl,mean))
tapply(mtcars$mpg,mtcars$cyl,mean)
debug(1s)
help(is)
debug(Is)
debug(is)
is()
``
library('xlsx')
fun(xlsx, xlsx)
require(xlsx)
library("rJava", lib.loc="~/R/win-library/3.6")
remove.packages("rJava", lib="~/R/win-library/3.6")
install.packages("rJava")
install.packages('RMySQL',type='source')
mysql --user-genome --host-genome-mysql.cse.ucsc.edu -A
ucscDb<-dbConnect(MySQL(), user="genome", host="genome-mysql.cse.ucsc.edu")
library('RMySQL')
ucscDb<-dbConnect(MySQL(), user="genome", host="genome-mysql.cse.ucsc.edu")
result<-dbGetQuery(ucscDb, "show databases;")
result
dbDisconnect(ucscDb)
result
hg19<-dbConnect(MySQL(), user="genome", db="hg19", host="genome-mysql.cse.ucsc.edu")
allTables<-dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListField(hg19, "affyU133Plus2")
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData<-dbReadTable(hg19, "affyU133Plus2")
head(affyU133Plus2)
head(affyData)
query<-dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis<-fetch(query)
quantile(affyMis$misMatches)
affyMisSmall<-fetch(query,n=10)
affyMisSmall
dbClearResult(query)
dim(affyMisSmall)
dbDisconnect(hg19)
source("http://bipoconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
source("https://bioconductor.org/biocLite.R")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install()
biocLite('rhdf5')
library(BiocManager)
biocLite('rhdf5')
biocLite("rhdf5")
BiocManager::available()
BiocManager::install(c("rhdf5"))
library(rhdf5)
created=h5createFile("example.h5")
created
created=h5createGroup("example.h5", "foo")
created=h5createGroup("example.h5", "baa")
created=h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
library(httr)
install.packages("httr")
library(httr)
install.packages("jsonLite")
y
install.packages("jsonlite")
library(jsonlite)
install.packages("httpuv")
library(httpuv)
oauth_endpoints("github")
myapp<-oauth_app(appname="Andrada_App", key="340369275041c3af69a2", secret="9e00f9a669b18ccd2824a396ae22fe1f4cc93179")
github_token<-oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken<-config(token=github_token)
req<-GET("https://api.github.com/users/jtleek/repos", gtoken)
json1=content(req'')
json1=content(req)
json2=jsonlite::fromJSON(tojson(json1))
json2=jsonlite::fromJSON(toJSON(json1))
json2[1,1"4"]
json2[1,1:4]
json2[1,1:8]
json2[1,"created_at"]
json2[,"created_at"]
json2[json2$full_name=="jtleek/datasharing", "created_at"]
install.paclages("utils")
install.packages("utils")
install.packages("utils")
install.packages("utils")
install.packages("utils")
remove.packages("RMySQL")
remove.packages("DBI")
install.packages("utils")
install.packages("utils")
install.packages("utils")
install.packages("utils")
install.packages("utils")
install.packages("utils")
help(read.fwf)
url<-https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
url<-"http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"
read.fwf(url, widths = 9, header=TRUE, sep=" ")
read.fwf(url, widths = 4, header=TRUE, sep=" ")
data<-read.fwf(url, widths = 9, header=TRUE, sep=" ")
data<-read.fwf(url, widths = 9, header=TRUE, skip=2)
data
data<-read.fwf(url, widths = 13, header=TRUE, skip=2)
data
data<-read.fwf(url, widths = c(-58,3), header=TRUE, skip=2)
data
data<-read.fwf(url, widths = c(-59,3), header=TRUE, skip=2)
data
data<-c(read.fwf(url, widths = c(-59,3), header=TRUE, skip=2))
is.vector(data)
sum(data)
data<-sum(read.fwf(url, widths = c(-59,3), header=TRUE, skip=2))
data<-sum(read.fwf(url, widths = c(-59,3), header=TRUE, skip=2))
data<-read.fwf(url, widths = c(-59,3), header=TRUE, skip=2)
header(data)
head(data)
data<-read.fwf(url, widths = c(-59,3), header=TRUE, skip=4)
head(data)
data<-read.fwf(url, widths = c(-59,3), header=TRUE, skip=2)
head(data)
data<-read.fwf(url, header=TRUE, skip=2)
data<-read.fwf(url, widths=62, header=TRUE, skip=2)
head(data)
is.data.frame(data)
data<-read.fwf(url, widths=c(-28,4), header=TRUE, skip=2)
head(data)
data<-read.fwf(url, widths=c(-28,4), header=TRUE, skip=4)
head(data)
data<-read.fwf(url, widths=c(-28,4), header=TRUE, skip=3)
head(data)
sum(data[,4])
data<-read.fwf(url, widths=c(-1,9,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3), header=TRUE, skip=3)
data<-read.fwf(url, widths=c(-1,9,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3), header=TRUE, skip=4)
data<-read.fwf(url, widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), header=TRUE, skip=4)
data<-read.fwf(url, widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
head(data)
sum(data[,4])
data
data[,4]
get<-c(data[,4])
sum(get)
url<-"http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"
data<-read.fwf(url, widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
head(data)
sum(data[,4])
data<-read.fwf(file=url, widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
sum(data[,4])
help(download.file)
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
url
getwd()
download.file(url, destfile="./R/Coursera_Data_Science_Specialization/GettingAndCleaningData")
download.file(url, destfile="./R/Coursera_Data_Science_Specialization/GettingAndCleaningData/acs.csv", method="curl")
acs<-download.file(url, destfile="./R/Coursera_Data_Science_Specialization/GettingAndCleaningData/acs.csv", method="curl")
head(acs)
is.data.frame(acs)
is.list(acs)
help(read.csv)
acsdata<-read.csv(csv, header=TRUE, sep=",")
acsdata<-read.csv(acs, header=TRUE, sep=",")
acs
acsdata=read.csv("./R/Coursera_Data_Science_Specialization/GettingAndCleaningData/acs.csv")
head(acsdata)
is.data.frame(acsdata)
acsdata[(ACR>10 & AGS==6),]
acsdata=read.csv("./R/Coursera_Data_Science_Specialization/GettingAndCleaningData/acs.csv", col.names= "RT", "SERIALNO", "DIVISION", "PUMA", "REGION", "ST",  "ADJUST", "WGTP", "NP", "TYPE", "ACR", "AGS", "BDS", "BLD", "BUS", "CONP", "ELEP", "FS")
colnames(acsdata)
acsdata[("ACR">10 & "AGS"==6),]
acsdata=read.csv("./R/Coursera_Data_Science_Specialization/GettingAndCleaningData/acs.csv")
acsdata[("ACR">10 & "AGS"==6),]
acsdata=read.csv("./R/Coursera_Data_Science_Specialization/GettingAndCleaningData/acs.csv")
head(acsdata)
acsdata[(acsdata$ACR>10 & acsdata$AGS==6),]
acsdata[(acsdata$ACR>10),]
acsdata[(acsdata$ACR>=3),]
acsdata[(acsdata$ACR>=1),]
acsdata[which(acsdata$ACR>=1),]
acsdata[which(acsdata$ACR>=3),]
acsdata[which(acsdata$ACR>=3 & acsdata$AGS==6),]
agricultureLogical<-acsdata[which(acsdata$ACR>=3 & acsdata$AGS==6),]
which(agricultureLogical)
acsLogical=ifelse((\acsdata$ACR>=3 & acsdata$AGS==6), TRUE, FALSE)
acsLogical=ifelse((acsdata$ACR>=3 & acsdata$AGS==6), TRUE, FALSE)
acsLogical
which(acsLogical)
setwd("C:/Users/andra/Documents/R/Coursera_Data_Science_Specialization/GettingAndCleaningData/week4/UCI_Har_Dataset")
setwd("C:/Users/andra/Documents/R/Coursera_Data_Science_Specialization/GettingAndCleaningData/week4/Har_Dataset")
subject_test<-read.table("./test/subject_test.txt")
X_test<-read.table("./test/X_test.txt")
y_test<-read.table("./test/y_test.txt")
subject_train<-read.table("./train/subject_train.txt")
X_train<-read.table("./train/X_train.txt")
y_train<-read.table("./train/y_train.txt")
head(subject_test)
head(X_train)
install.packages("reshape2")
library(reshape2)
help(melt)
help("cbind")
trainBind<-cbind(subject_test, y_test, X_test)
head(trainBind)
testBind<-cbind(subject_test, y_test, X_test)
trainBind<-cbind(subject_train, y_train, X_train)
